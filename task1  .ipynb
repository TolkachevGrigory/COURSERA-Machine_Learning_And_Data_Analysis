{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# сходство текстов "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "В этом задании вы познакомитесь с некоторыми базовыми методами из линейной алгебры, реализованными в пакете SciPy — в частности, с методами подсчета косинусного расстояния и решения систем линейных уравнений. Обе эти задачи еще много раз встретятся нам в специализации. Так, на решении систем линейных уравнений основана настройка линейных моделей — очень большого и важного класса алгоритмов машинного обучения. Косинусное расстояние же часто используется в анализе текстов для измерения сходства между ними."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дан набор предложений, скопированных с Википедии. Каждое из них имеет \"кошачью тему\" в одном из трех смыслов:\n",
    "\n",
    "кошки (животные)\n",
    "UNIX-утилита cat для вывода содержимого файлов\n",
    "версии операционной системы OS X, названные в честь семейства кошачьих\n",
    "Ваша задача — найти два предложения, которые ближе всего по смыслу к расположенному в самой первой строке. В качестве меры близости по смыслу мы будем использовать косинусное расстояние.\n",
    "\n",
    "sentences.txt\n",
    "Выполните следующие шаги:\n",
    "\n",
    "Скачайте файл с предложениями (sentences.txt).\n",
    "Каждая строка в файле соответствует одному предложению. Считайте их, приведите каждую к нижнему регистру с помощью строковой функции lower().\n",
    "Произведите токенизацию, то есть разбиение текстов на слова. Для этого можно воспользоваться регулярным выражением, которое считает разделителем любой символ, не являющийся буквой: re.split('[^a-z]', t). Не забудьте удалить пустые слова после разделения.\n",
    "Составьте список всех слов, встречающихся в предложениях. Сопоставьте каждому слову индекс от нуля до (d - 1), где d — число различных слов в предложениях. Для этого удобно воспользоваться структурой dict.\n",
    "Создайте матрицу размера n * d, где n — число предложений. Заполните ее: элемент с индексом (i, j) в этой матрице должен быть равен количеству вхождений j-го слова в i-е предложение. У вас должна получиться матрица размера 22 * 254.\n",
    "Найдите косинусное расстояние от предложения в самой первой строке (In comparison to dogs, cats have not undergone...) до всех остальных с помощью функции scipy.spatial.distance.cosine. Какие номера у двух предложений, ближайших к нему по этому расстоянию (строки нумеруются с нуля)? Эти два числа и будут ответами на задание. Само предложение (In comparison to dogs, cats have not undergone... ) имеет индекс 0.\n",
    "Запишите полученные числа в файл, разделив пробелом. Обратите внимание, что файл должен состоять из одной строки, в конце которой не должно быть переноса. Пример файла с решением вы можете найти в конце задания (submission-1.txt).\n",
    "Совпадают ли ближайшие два предложения по тематике с первым? Совпадают ли тематики у следующих по близости предложений?\n",
    "Разумеется, использованный вами метод крайне простой. Например, он не учитывает формы слов (так, cat и cats он считает разными словами, хотя по сути они означают одно и то же), не удаляет из текстов артикли и прочие ненужные слова. Позже мы будем подробно изучать анализ текстов, где выясним, как достичь высокого качества в задаче поиска похожих предложений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLineAndWord(path):\n",
    "    file = ''\n",
    "    linelist = []\n",
    "    with open(path) as fileline:\n",
    "        k = 0\n",
    "        for line in fileline:\n",
    "            file = file + str(line)\n",
    "            linelist.append(re.split('[^a-z]', line.lower()))\n",
    "            k+=1\n",
    "            \n",
    "    number_line = sum(1 for line in open(path, 'r'))\n",
    "    file = file.lower()\n",
    "    file = re.split('[^a-z]', file)\n",
    "    filelist = ' '.join(file).split()\n",
    "    dictionary = {} \n",
    "    k = 0\n",
    "    for i in filelist:\n",
    "        if not(i in dictionary):\n",
    "            dictionary[i] = k\n",
    "            k+=1\n",
    "    \n",
    "    return dictionary, linelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем слова в предложении line должен быть списком\n",
    "def count_word(word, line):\n",
    "    e = 0\n",
    "    for element in line:\n",
    "        if element == word:\n",
    "            e+=1\n",
    "    return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix(path):\n",
    "    dictionary, linelist = getLineAndWord(path)\n",
    "    \n",
    "    matrix = np.zeros((len(linelist),len(dictionary)))\n",
    "    for i in range(len(linelist)):\n",
    "        for e in dictionary:\n",
    "            matrix[i, dictionary.get(e)] = count_word(e, linelist[i])\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9527544408738466\n",
      "2 0.8644738145642124\n",
      "3 0.8951715163278082\n",
      "4 0.7770887149698589\n",
      "5 0.9402385695332803\n",
      "6 0.7327387580875756\n",
      "7 0.9258750683338899\n",
      "8 0.8842724875284311\n",
      "9 0.9055088817476932\n",
      "10 0.8328165362273942\n",
      "11 0.8804771390665607\n",
      "12 0.8396432548525454\n",
      "13 0.8703592552895671\n",
      "14 0.8740118423302576\n",
      "15 0.9442721787424647\n",
      "16 0.8406361854220809\n",
      "17 0.956644501523794\n",
      "18 0.9442721787424647\n",
      "19 0.8885443574849294\n",
      "20 0.8427572744917122\n",
      "21 0.8250364469440588\n"
     ]
    }
   ],
   "source": [
    "for i in range(mat.shape[0]-1):\n",
    "    print(i+1, distance.cosine(mat[0, :],mat[i+1, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(path):\n",
    "    mat = get_matrix(path)\n",
    "    listresult = {}\n",
    "    for i in range(mat.shape[0]-1):\n",
    "        listresult[i] = distance.cosine(mat[0, :],mat[i+1, :])\n",
    "    return listresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_assemble = get_result('/eos/user/g/gtolkach/SWAN_projects/cursera/sentences.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 4\n"
     ]
    }
   ],
   "source": [
    "sort_result = sorted(res_assemble.items(), key=lambda x: x[1])\n",
    "print(sort_result[0][0]+1, sort_result[1][0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
